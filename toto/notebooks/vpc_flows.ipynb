{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58854e0d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false,
    "scrolled": true,
    "tags": [
     "unsafe_output"
    ]
   },
   "outputs": [],
   "source": [
    "# make sure the PWD is set to the main `toto` directory\n",
    "%cd ..\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from data.util.dataset import MaskedTimeseries\n",
    "from inference.forecaster import TotoForecaster\n",
    "from model.toto import Toto\n",
    "\n",
    "# These lines make gpu execution in CUDA deterministic\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1e9493-44ff-4c4e-b8af-93f3f70a057b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-05-01T01:50:43.953491Z",
     "iopub.status.busy": "2025-05-01T01:50:43.952996Z",
     "iopub.status.idle": "2025-05-01T01:50:43.994997Z",
     "shell.execute_reply": "2025-05-01T01:50:43.994460Z",
     "shell.execute_reply.started": "2025-05-01T01:50:43.953467Z"
    },
    "frozen": false,
    "tags": [
     "unsafe_output"
    ]
   },
   "source": [
    "# Time series forecasting with Toto\n",
    "\n",
    "In this notebook, you'll learn how to perform inference with Toto for multivariate time series forecasting on the classic ETT dataset. Toto is a foundation model used for *zero-shot* forecasting,\n",
    "meaning no training is required. We simply provide the historical context of a time series to Toto as input, and Toto produces forecasts of the desired length.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "You'll need to run this with a CUDA-capable device. In order to get the fastest inference performance, please use an Ampere or newer architecture, as these support the xFormers fused kernel implementations for SwiGLU and Memory-Efficient Attention.\n",
    "\n",
    "Make sure you've cloned the repo and installed dependencies with `pip install -r requirements.txt`. When running this notebook, make sure the working directory is set to `<repository_root>/toto`.\n",
    "\n",
    "This notebook also assumes that you've downloaded the `ETT-small` dataset locally. It can be obtained from the [official repo](https://github.com/zhouhaoyi/ETDataset).\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6875fc8c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false,
    "tags": [
     "unsafe_output"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ── 1. BASIC SETTINGS ────────────────────────────────────────────────────────\n",
    "start_date   = \"2025-01-01\"       # inclusive\n",
    "end_date     = \"2025-01-07\"       # exclusive: runs to 2025-01-06 23:59\n",
    "freq         = \"1min\"             # aggregation window (≤10 min is valid for VPC logs)\n",
    "rng          = np.random.default_rng(42)\n",
    "\n",
    "src_public   = \"198.51.100.1\"     # static Internet sender\n",
    "servers = [                       # our two targets inside the VPC\n",
    "    {\"dstaddr\": \"10.0.0.1\", \"eni\": \"eni-0123456789abcdef0\"},\n",
    "    {\"dstaddr\": \"10.0.0.2\", \"eni\": \"eni-0123456789abcdef1\"},\n",
    "]\n",
    "\n",
    "base_packets          = 120       # mean packets per minute at 100 % load\n",
    "base_bytes_per_packet = 800       # mean TCP payload size in bytes\n",
    "flow_type             = \"14\" # constant for every row\n",
    "\n",
    "# ── 2. CLEAR SINUSOIDAL PATTERN ──────────────────────────────────────────────\n",
    "def traffic_factor(ts):\n",
    "    \"\"\"Return a very clear sinusoidal traffic pattern with daily periodicity.\"\"\"\n",
    "    # Calculate hours since start as a float\n",
    "    start_ts = pd.Timestamp(\"2025-01-01\")\n",
    "    hours_since_start = (ts - start_ts).total_seconds() / 3600.0\n",
    "    \n",
    "    # Create 24-hour sinusoidal cycle with large amplitude\n",
    "    # Peak at hour 12 (noon), trough at hour 0 (midnight)\n",
    "    angle = 2 * np.pi * hours_since_start / 24.0\n",
    "    \n",
    "    # Large amplitude sine wave: range from 0.2 to 1.8 (20% to 180% of baseline)\n",
    "    # This will make the pattern very obvious\n",
    "    return 1.0 + 0.8 * np.sin(angle - np.pi/2)  # -π/2 phase shift so peak is at noon\n",
    "\n",
    "# ── 3. BUILD THE RECORDS ─────────────────────────────────────────────────────\n",
    "index = pd.date_range(start=start_date, end=end_date,\n",
    "                      freq=freq, inclusive=\"left\")\n",
    "\n",
    "rows = []\n",
    "for ts in index:\n",
    "    f = traffic_factor(ts)\n",
    "    for srv in servers:\n",
    "        # Almost no noise - just the pure sinusoidal pattern\n",
    "        pkts  = max(1, int(base_packets * f * (1 + rng.normal(0, 0.005))))  # Tiny noise: 0.5%\n",
    "        bytes_ = pkts * int(base_bytes_per_packet *\n",
    "                            (1 + rng.normal(0, 0.002)))  # Even tinier noise: 0.2%\n",
    "\n",
    "        rows.append({\n",
    "            \"timestamp\"    : ts.isoformat(),\n",
    "            \"interface-id\" : srv[\"eni\"],\n",
    "            \"srcaddr\"      : src_public,\n",
    "            \"dstaddr\"      : srv[\"dstaddr\"],\n",
    "            \"type\"         : flow_type,\n",
    "            \"packets\"      : pkts,\n",
    "            \"bytes\"        : bytes_,\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# ── 4. SAVE & QUICK PEEK ────────────────────────────────────────────────────\n",
    "df.to_csv(\"custom_flow_logs.csv\", index=False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e25e6b-0213-44f3-8c5b-bd6a4ff19dbe",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false,
    "tags": [
     "unsafe_output"
    ]
   },
   "source": [
    "## Preprocess data\n",
    "\n",
    "In the following section, we prepare the data in the expected input format of Toto.\n",
    "\n",
    "Toto expects inputs to be multivariate time series data in the shape\n",
    "\n",
    "$\\text{Variate} \\times \\text{Time Steps}$\n",
    "\n",
    "or, with optional batch dimension:\n",
    "\n",
    "$\\text{Batch} \\times \\text{Variate} \\times \\text{Time Steps}$\n",
    "\n",
    "For illustration, we'll try to predict the last 96 steps of the ETTm1 time series across its 7 covariates. We'll do this using the preceding 1024 steps as context. 2048 gives a good balance of speed vs. performance; you may want to experiment with different context lengths depending on your dataset. Toto was trained with a max context length of 4096, but can extrapolate to even longer contexts. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75cadbd-8f12-4c06-9278-5b4e0a884eeb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false,
    "tags": [
     "unsafe_output"
    ]
   },
   "outputs": [],
   "source": [
    "context_length = 4096\n",
    "prediction_length = 336"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d3d51e-0f1c-4e80-ae25-65fb3389bdaf",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false,
    "tags": [
     "unsafe_output"
    ]
   },
   "source": [
    "Slice the ETTm1 data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6673f65d-9329-468f-8a72-be89552934b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"custom_flow_logs.csv\", parse_dates=[\"timestamp\"])\n",
    "\n",
    "\n",
    "df = (\n",
    "    pd.read_csv(\"custom_flow_logs.csv\")\n",
    "    .assign(date=lambda df: pd.to_datetime(df[\"timestamp\"]))\n",
    "    .assign(timestamp_seconds=lambda df: (df.date - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s'))\n",
    "\n",
    ")\n",
    "\n",
    "df.reindex(columns=[\"date\"] + [col for col in df.columns if col != \"date\"]).drop(columns=[\"timestamp\"])  # Remove timestamp column\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7283f4ef",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false,
    "tags": [
     "unsafe_output"
    ]
   },
   "outputs": [],
   "source": [
    "feature_columns = [\"packets\", \"bytes\"]\n",
    "n_variates = len(feature_columns)\n",
    "interval = 60 * 15  # 15-min intervals\n",
    "input_df = df.iloc[-(context_length+prediction_length):-prediction_length]\n",
    "target_df = df.iloc[-prediction_length:]\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "input_series = torch.from_numpy(input_df[feature_columns].values.T).to(torch.float).to(DEVICE)\n",
    "input_series.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f721869-5efc-4d28-b021-0a7f109d8bfe",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false,
    "tags": [
     "unsafe_output"
    ]
   },
   "source": [
    "Add timestamp features to the data. Note: the current version of Toto does not use these features; it handles series of different time resolutions implicitly. However, future versions may take this into account, so the API expects timestamps to be passed in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2146414e-b8e7-418b-b693-8f8b4af6bbbc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false,
    "tags": [
     "unsafe_output"
    ]
   },
   "outputs": [],
   "source": [
    "timestamp_seconds = torch.from_numpy(input_df.timestamp_seconds.values.T).expand((n_variates, context_length)).to(input_series.device)\n",
    "time_interval_seconds=torch.full((n_variates,), interval).to(input_series.device)\n",
    "start_timestamp_seconds = timestamp_seconds[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081235ed-7663-4819-8c5c-6b1a3461184b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false,
    "tags": [
     "unsafe_output"
    ]
   },
   "source": [
    "Toto expects its inputs in the form of a `MaskedTimeseries` dataclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae6dadb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false,
    "tags": [
     "unsafe_output"
    ]
   },
   "outputs": [],
   "source": [
    "inputs = MaskedTimeseries(\n",
    "    series=input_series,\n",
    "    # The padding mask should be the same shape as the input series.\n",
    "    # It should be 0 to indicate padding and 1 to indicate valid values.\n",
    "    padding_mask=torch.full_like(input_series, True, dtype=torch.bool),\n",
    "    # The ID mask is used for packing unrelated time series along the Variate dimension.\n",
    "    # This is used in training, and can also be useful for large-scale batch inference in order to\n",
    "    # process time series of different numbers of variates using batches of a fixed shape.\n",
    "    # The ID mask controls the channel-wise attention; variates with different IDs cannot attend to each other.\n",
    "    # If you're not using packing, just set this to zeros.\n",
    "    id_mask=torch.zeros_like(input_series),\n",
    "    # As mentioned above, these timestamp features are not currently used by the model;\n",
    "    # however, they are reserved for future releases.\n",
    "    timestamp_seconds=timestamp_seconds,\n",
    "    time_interval_seconds=time_interval_seconds,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8142215b-9cb7-4d82-82b6-91342d3973aa",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false,
    "tags": [
     "unsafe_output"
    ]
   },
   "source": [
    "Now our data is ready!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3a0b408-ba18-4cf0-8fc8-c9bb842b4f1b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false,
    "tags": [
     "unsafe_output"
    ]
   },
   "source": [
    "## Load Toto checkpoint\n",
    "\n",
    "Download a Toto checkpoint from Hugging Face (TBD) to a local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef2e244",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false,
    "tags": [
     "unsafe_output"
    ]
   },
   "outputs": [],
   "source": [
    "toto = Toto.from_pretrained('Datadog/Toto-Open-Base-1.0')\n",
    "toto.to(DEVICE)\n",
    "\n",
    "# Optionally enable Torch's JIT compilation to speed up inference. This is mainly\n",
    "# helpful if you want to perform repeated inference, as the JIT compilation can\n",
    "# take time to wrm up.\n",
    "toto.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8fdd44-da56-4235-9e77-bc2ffd60d65a",
   "metadata": {},
   "source": [
    "We generate multistep, autoregressive forecasts using the `TotoForecaster` class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5b9056-0de7-4a55-a98b-6413259bd22f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false,
    "tags": [
     "unsafe_output"
    ]
   },
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "DEVICE   = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "interval = 60 * 15                       # 900 s\n",
    "seq_len  = context_length                # whatever slice you chose\n",
    "\n",
    "# ── series  (1, 6, seq_len) ────────────────────────────────────────────────\n",
    "series_tensor = (\n",
    "    torch.tensor(input_df[feature_columns].values.T, dtype=torch.float32)\n",
    "         .unsqueeze(0)                   # add batch dim\n",
    "         .to(DEVICE)\n",
    ")\n",
    "\n",
    "# ── timestamp_seconds  (1, 6, seq_len) ─────────────────────────────────────\n",
    "ts_np = (input_df.index.view(\"int64\") // 1_000_000_000)\n",
    "timestamp_seconds = (\n",
    "    torch.from_numpy(ts_np)\n",
    "         .long()\n",
    "         .unsqueeze(0).unsqueeze(0)      # batch, variate\n",
    "         .repeat(1, n_variates, 1)\n",
    "         .to(DEVICE)\n",
    ")\n",
    "\n",
    "# ── time_interval_seconds  (1, 6) ──────────────────────────────────────────\n",
    "time_interval_seconds = torch.full(\n",
    "    (1, n_variates),\n",
    "    fill_value=interval,\n",
    "    dtype=torch.long,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "# ── Build the batch object *with padding_mask* ─────────────────────────────\n",
    "inputs = SimpleNamespace(\n",
    "    series=series_tensor,\n",
    "    timestamp_seconds=timestamp_seconds,\n",
    "    time_interval_seconds=time_interval_seconds,\n",
    "    padding_mask=torch.ones_like(series_tensor, dtype=torch.bool),  # Create a mask of all True values\n",
    "    id_mask=None,        # optional; keep None if you have only one “item”\n",
    ")\n",
    "\n",
    "# ── Forecast ────────────────────────────────────────────────────────────────\n",
    "forecaster = TotoForecaster(toto.model)\n",
    "forecast = forecaster.forecast(\n",
    "    inputs,\n",
    "    prediction_length=prediction_length,\n",
    "    num_samples=256,\n",
    "    samples_per_batch=256,\n",
    "    use_kv_cache=True,\n",
    ")\n",
    "\n",
    "print(\"forecast mean shape:\", forecast.mean.shape)  # (1, 6, prediction_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d26bc5c-3129-45ff-8061-aefdb0981a52",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## Visualize the forecasts\n",
    "\n",
    "We can plot our forecasts and confidence intervals against the ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32c8266",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false,
    "tags": [
     "unsafe_output"
    ]
   },
   "outputs": [],
   "source": [
    "DARK_GREY = \"#1c2b34\"\n",
    "BLUE = \"#3598ec\"\n",
    "PURPLE = \"#7463e1\"\n",
    "LIGHT_PURPLE = \"#d7c3ff\"\n",
    "PINK = \"#ff0099\"\n",
    "\n",
    "matplotlib.rc(\"axes\", edgecolor=DARK_GREY)\n",
    "fig = plt.figure(figsize=(12, 6), layout=\"tight\", dpi=150)\n",
    "plt.suptitle(\"Toto Forecasts (ETTm1)\")\n",
    "\n",
    "for i, feature in enumerate(feature_columns):\n",
    "    # Configure axes\n",
    "    plt.subplot(n_variates, 1, i + 1)\n",
    "    if i != 6:\n",
    "        # only show x tick labels on the bottom subplot\n",
    "        fig.gca().set_xticklabels([])\n",
    "    fig.gca().tick_params(axis=\"x\", color=DARK_GREY, labelcolor=DARK_GREY)\n",
    "    fig.gca().tick_params(axis=\"y\", color=DARK_GREY, labelcolor=DARK_GREY)\n",
    "    fig.gca().yaxis.set_label_position(\"right\")\n",
    "    plt.ylabel(feature)\n",
    "    plt.xlim(input_df.date.iloc[-960], target_df.date.iloc[-1])\n",
    "    plt.axvline(target_df.date.iloc[0], color=PINK, linestyle=\":\")\n",
    "\n",
    "    # Plot ground truth\n",
    "    plt.plot(input_df[\"date\"], input_df[feature], color=BLUE)\n",
    "    plt.plot(target_df[\"date\"], target_df[feature], color=BLUE)\n",
    "\n",
    "    # Plot point forecasts\n",
    "    plt.plot(\n",
    "        target_df[\"date\"],\n",
    "        np.median(forecast.samples.squeeze()[i].cpu(), axis=-1),\n",
    "        color=PURPLE,\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "\n",
    "    # Plot quantiles\n",
    "    alpha = 0.05\n",
    "    qs = forecast.samples.quantile(q=torch.tensor([alpha, 1 - alpha], device=forecast.samples.device), dim=-1)\n",
    "    plt.fill_between(\n",
    "        target_df[\"date\"],\n",
    "        qs[0].squeeze()[i].cpu(),\n",
    "        qs[1].squeeze()[i].cpu(),\n",
    "        color=LIGHT_PURPLE,\n",
    "        alpha=0.8,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73399593-5d4a-423f-8be7-ee5173dac454",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dd-sharing": {
   "allowed_groups": [
    "subproduct-datascience",
    "combined-data-science",
    "team-appliedai-foundationmodelsresearch",
    ""
   ],
   "allowed_users": [
    ""
   ],
   "retention_period": "90"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
